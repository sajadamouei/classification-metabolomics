{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm > /dev/null 2>&1\n",
    "#!pip install ipywidgets > /dev/null 2>&1\n",
    "#!gdown -V > /dev/null 2>&1\n",
    "#!gdown --folder url -O /content/data > /dev/null 2>&1\n",
    "\n",
    "# Import necessary libraries and functions\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from time import time\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import (StratifiedKFold, cross_val_score, GridSearchCV,\n",
    "                                     train_test_split)\n",
    "from sklearn.metrics import (balanced_accuracy_score, classification_report,\n",
    "                             matthews_corrcoef, confusion_matrix, mean_squared_error,\n",
    "                             roc_curve, auc, roc_auc_score, accuracy_score,\n",
    "                             f1_score, precision_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "# Copy Datasets\n",
    "source_file_path = '/content/drive/MyDrive/PhD/1-DEDProject/8-ifocus-dataset/find biomarker in the metabolomics dataset/classification/datasets/data.zip'\n",
    "destination_file_path = '/content/data.zip'\n",
    "shutil.copy(source_file_path, destination_file_path)\n",
    "\n",
    "# Uzip the zipped dataset file\n",
    "zip_file_path = '/content/data.zip'\n",
    "extract_to_path = '/content/data/'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "############################################################################################# Plots\n",
    "# Function to plot histograms for different performance metrics\n",
    "def plot_histograms(auc_list, test_acc_list, mcc_list, bal_acc_list, model_name, method_name):\n",
    "    metrics = [auc_list, test_acc_list, mcc_list, bal_acc_list]\n",
    "    metric_names = [\"AUC\", \"Test Accuracy\", \"MCC\", \"Balanced Accuracy\"]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # iterate over the metrics and plot histogram\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i + 1)  # 2 rows, 2 columns\n",
    "        plt.hist(metric, bins=20, edgecolor='black', alpha=0.7)\n",
    "        plt.title(metric_names[i])\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Constructing the filename and saving the figure\n",
    "    directory = \"/content/report/plots\"\n",
    "    filename = os.path.join(directory, f\"{model_name}_{method_name}.png\")\n",
    "\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot AUC with error bars for different models and methods\n",
    "def plot_auc_with_error_bars(results_df):\n",
    "    # Extracting relevant data for plotting\n",
    "    labels = results_df[\"Model\"] + \"-\" + results_df[\"Feature Reduction Method\"]\n",
    "    auc_means = results_df[\"AUC Mean\"].values\n",
    "    auc_stds = results_df[\"AUC Std\"].values\n",
    "\n",
    "    # Setting the figure size and creating the bar plot with error bars\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.bar(range(len(labels)), auc_means, yerr=auc_stds, align='center', alpha=0.7, ecolor='black', capsize=10)\n",
    "    plt.ylabel('AUC')\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n",
    "\n",
    "    # Annotations for better clarity\n",
    "    for i, v in enumerate(auc_means):\n",
    "        plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', va='bottom', fontsize=8, color='black')\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.title('AUC with Error Bars for Different ML Model-FR Method Combinations', y=1.05)  # Adjust title position\n",
    "\n",
    "    # Saving the plot\n",
    "    plt.savefig(\"/content/report/auc_barplot_with_error_bars.png\", bbox_inches='tight')\n",
    "    plt.close()  # Close the figure after saving to free up memory    \n",
    "\n",
    "def plot_performance_heatmap(df, metric, save_path):\n",
    "\n",
    "  df[['Mean', 'CI']] = df[metric].str.split('±', expand=True)\n",
    "  df['Mean'] = df['Mean'].astype(float)\n",
    "\n",
    "  # Creating a pivot table for the heatmap\n",
    "  pivot_table = df.pivot(\"Model\", \"Feature Reduction Method\", \"Mean\")\n",
    "\n",
    "  # Plotting the heatmap\n",
    "  plt.figure(figsize=(10, 8))\n",
    "  ax = sns.heatmap(pivot_table, annot=True, fmt=\".4f\", cmap=\"YlGnBu\")\n",
    "\n",
    "  # Annotation settings\n",
    "  fontsize_mean = 10  # Font size for the mean values\n",
    "  fontsize_ci = 8    # Font size for the confidence intervals\n",
    "  mean_color = 'white'  # Color for the mean values\n",
    "  ci_color = 'darkorange'   # Color for the confidence intervals\n",
    "\n",
    "  # Adding the confidence interval and mean to the heatmap cells\n",
    "  for i, row in enumerate(pivot_table.values):\n",
    "      for j, _ in enumerate(row):\n",
    "          mean_value = pivot_table.iloc[i, j]\n",
    "          mean_text = f\"{mean_value:.4f}\"\n",
    "          ci_text = df.loc[(df['Model'] == pivot_table.index[i]) & (df['Feature Reduction Method'] == pivot_table.columns[j]), 'CI'].values[0]\n",
    "\n",
    "          # Positioning and color settings for annotations\n",
    "          #ax.text(j + 0.5, i + 0.3, mean_text, horizontalalignment='center', verticalalignment='center', color=mean_color, fontsize=fontsize_mean)\n",
    "          ax.text(j + 0.5, i + 0.7, f'±{ci_text}', horizontalalignment='center', verticalalignment='center', color=ci_color, fontsize=fontsize_ci)\n",
    "\n",
    "  plt.title(f'Heatmap of {metric} across Models and FR Methods')\n",
    "  plt.tight_layout()\n",
    "\n",
    "  # Save the heatmap\n",
    "  plt.savefig(save_path)\n",
    "  plt.close()\n",
    "\n",
    "\n",
    "########################################################################################### Load dataset\n",
    "# Define a function to load the dataset from an Excel file\n",
    "def load_dataset(sheet_name, remove_unknowns=True):\n",
    "    path = '/content/data/m1_esi_plus_minus_norm.xlsx'\n",
    "    dataset = pd.read_excel(path, sheet_name=sheet_name, header=0)\n",
    "    dataset = dataset.sample(frac=1, random_state=666).reset_index(drop=True)\n",
    "    dataset = dataset.drop(columns=['eye', 'gender', 'age'])\n",
    "    # Optionally remove columns that start with 'unknown'\n",
    "    if remove_unknowns:\n",
    "        dataset = dataset.loc[:, ~dataset.columns.str.startswith('unknown')]\n",
    "    return dataset\n",
    "\n",
    "# Define a function to prepare the data for training\n",
    "def prepare_data(dataset):\n",
    "    # Extract labels for training\n",
    "    train_label = dataset['class']\n",
    "    # Drop the first and last columns from the dataset for training data\n",
    "    train_data = dataset.drop(columns=[dataset.columns[0], dataset.columns[-1]])\n",
    "    return train_data, train_label, dataset.columns.tolist()  \n",
    "\n",
    "\n",
    "# Define a function to get the dataset and preprocess it based on feature selection\n",
    "def get_data(sheet_name, train_features):\n",
    "    if train_features == 'Only known metabolites':\n",
    "        dataset = load_dataset(sheet_name, remove_unknowns=True)\n",
    "    else:\n",
    "        dataset = load_dataset(sheet_name, remove_unknowns=False)\n",
    "    return prepare_data(dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
